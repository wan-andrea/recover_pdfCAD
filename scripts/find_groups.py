"""
Spatial Group Clustering for PDF Shapes
=======================================

This script performs post-processing on the JSON data generated by the PDF Shape Analyzer.
It identifies recurring "clusters" or "groups" of shapes that appear together in fixed 
spatial arrangements (e.g., a "cubicle" made of a desk, chair, and cabinet).

The algorithm works by:
1. Constructing a spatial graph where nodes are shape instances and edges represent 
   relative distance vectors.
2. Mining "frequent edges" (pairs of shapes that consistently appear at the same relative 
   distance/angle across the document).
3. Assembling these frequent edges into connected components (clusters).
4. Classifying these clusters into unique "Group Types" based on their composition.

Inputs:
    --input (default: 'output_data.json'): The instance registry containing shape IDs, 
      page numbers, and global coordinates.

Outputs:
    --output (default: 'detected_groups.json'): A structured registry of detected groups, 
      defining their composition (member shapes) and listing all instances found.

Configuration:
    - SEARCH_RADIUS: Maximum distance (PDF units) to search for neighbors.
    - MIN_OCCURRENCES: Minimum number of times a spatial pattern must repeat to be 
      considered a valid group.

Usage:
    python find_groups.py --input output_data.json --output detected_groups.json
"""

import json
import numpy as np
import argparse
from sklearn.neighbors import KDTree
from collections import defaultdict, Counter

# CONFIG
SEARCH_RADIUS = 500.0  # How close items must be to be considered part of a group (units)
MIN_OCCURRENCES = 3    # A group must appear at least this many times to be valid

def load_data(json_file):
    with open(json_file, 'r') as f:
        return json.load(f)

def get_instance_centroid(instance):
    """Calculates the global (page) coordinates of the shape center."""
    # Transform matrix: [a, b, c, d, e, f]
    # x' = a*x + c*y + e
    # y' = b*x + d*y + f
    # We use the center of the local bbox
    bbox = instance['bbox_local'] # minx, miny, maxx, maxy
    local_cx = (bbox[0] + bbox[2]) / 2
    local_cy = (bbox[1] + bbox[3]) / 2
    
    m = instance['transform_matrix']
    global_x = m[0]*local_cx + m[2]*local_cy + m[4]
    global_y = m[1]*local_cx + m[3]*local_cy + m[5]
    
    return np.array([global_x, global_y])

def find_spatial_groups(data):
    instances = data['instances']
    
    # 1. Organize instances by Page (groups can't span pages)
    pages = defaultdict(list)
    for inst in instances:
        pages[inst['page']].append(inst)
        
    # We will look for "signatures".
    # A signature is a frozenset of: (ShapeID, Relative_X, Relative_Y)
    # Relative to what? The "anchor" (top-left-most item in the group).
    
    # Heuristic approach: Neighbor Graph
    # -----------------------------------
    # Store connections: "Shape A" sees "Shape B" at "Delta Vector (dx, dy)"
    # We round dx, dy to avoid floating point mismatch.
    
    connection_counts = Counter() 
    
    print(f"Analyzing {len(instances)} instances across {len(pages)} pages...")
    
    for page_num, page_insts in pages.items():
        if len(page_insts) < 2: continue
        
        # Calculate centroids for all items on this page
        centroids = np.array([get_instance_centroid(inst) for inst in page_insts])
        ids = [inst['shape_id'] for inst in page_insts]
        
        # Build KDTree for efficient radius search
        tree = KDTree(centroids)
        
        # Find neighbors for every point
        # query_radius returns indices of neighbors within distance
        indices = tree.query_radius(centroids, r=SEARCH_RADIUS)
        
        for i, neighbors in enumerate(indices):
            anchor_id = ids[i]
            anchor_pos = centroids[i]
            
            for n_idx in neighbors:
                if i == n_idx: continue # Skip self
                
                neighbor_id = ids[n_idx]
                neighbor_pos = centroids[n_idx]
                
                # Calculate Delta Vector
                delta = neighbor_pos - anchor_pos
                
                # Round to nearest 1.0 unit (tolerance for slight misalignment)
                dx = round(delta[0], 1)
                dy = round(delta[1], 1)
                
                # Create a signature: "Shape X sees Shape Y at (dx, dy)"
                # We sort the IDs to ensure A->B is same as B<-A (with inverted vector)
                # But treating it directed is easier for now: Anchor -> Neighbor
                signature = (anchor_id, neighbor_id, dx, dy)
                connection_counts[signature] += 1

    # 2. Filter Weak Connections
    # --------------------------
    # Only keep connections that appear frequently (e.g. > 3 times)
    strong_connections = {sig for sig, count in connection_counts.items() if count >= MIN_OCCURRENCES}
    
    print(f"Found {len(strong_connections)} frequent pairwise spatial relationships.")
    
    # 3. Assemble Clusters (Graph Traversal)
    # --------------------------------------
    # We now have edges. We need to find connected components.
    # But wait, a "connection" implies a rigid relative position.
    
    # Let's re-scan the pages and actually group the objects using these strong rules.
    
    groups = []
    
    for page_num, page_insts in pages.items():
        # Map local index to instance object for easy access
        # Also need centroids again
        centroids = np.array([get_instance_centroid(inst) for inst in page_insts])
        
        # Create an adjacency list for this page based ONLY on strong connections
        adj = defaultdict(list)
        
        # Brute force checks for this page (or use KDTree again if slow)
        # For simplicity/speed on small page counts:
        n = len(page_insts)
        for i in range(n):
            for j in range(n):
                if i == j: continue
                
                id_i = page_insts[i]['shape_id']
                id_j = page_insts[j]['shape_id']
                delta = centroids[j] - centroids[i]
                dx = round(delta[0], 1)
                dy = round(delta[1], 1)
                
                if (id_i, id_j, dx, dy) in strong_connections:
                    adj[i].append(j)

        # Find connected components (BFS)
        visited = set()
        for i in range(n):
            if i in visited: continue
            if i not in adj and not adj[i]: continue # Skip isolated nodes? Or keep them?
            
            # Start a new group traversal
            queue = [i]
            visited.add(i)
            cluster_indices = []
            
            while queue:
                curr = queue.pop(0)
                cluster_indices.append(curr)
                
                for neighbor in adj[curr]:
                    if neighbor not in visited:
                        visited.add(neighbor)
                        queue.append(neighbor)
            
            # A cluster is formed
            if len(cluster_indices) > 1:
                # This is a group!
                group_instance = {
                    "page": page_num,
                    "members": [page_insts[k]['instance_id'] for k in cluster_indices],
                    "member_shapes": [page_insts[k]['shape_id'] for k in cluster_indices],
                    "centroid_avg": np.mean(centroids[cluster_indices], axis=0).tolist()
                }
                groups.append(group_instance)
    
    # 4. Classify Group Types
    # -----------------------
    # Many groups are identical. We need to give them a "Group Type ID".
    # A Group Type is defined by the sorted list of shape IDs it contains (bag of words)
    # AND their relative positions (geometry).
    # For simplicity, let's just use the sorted tuple of shape IDs as a loose "Type".
    
    group_types = defaultdict(list)
    for g in groups:
        # Create a signature: Sorted Tuple of Shape IDs
        # e.g. (1, 1, 5, 8) -> Two Shape-1s, one Shape-5, one Shape-8
        sig = tuple(sorted(g['member_shapes']))
        group_types[sig].append(g)
        
    print(f"Identified {len(groups)} group instances across {len(group_types)} unique group configurations.")
    
    return group_types, groups

def export_groups(group_types, groups, output_file):
    output = {
        "metadata": {
            "total_groups": len(groups),
            "unique_configurations": len(group_types)
        },
        "group_definitions": {},
        "group_instances": groups
    }
    
    for i, (sig, insts) in enumerate(group_types.items()):
        output["group_definitions"][str(i+1)] = {
            "composition": list(sig),
            "count": len(insts),
            "semantic_label": "" # e.g. "Double Cubicle"
        }
        # Back-tag instances
        for inst in insts:
            inst['group_type_id'] = i+1
            
    with open(output_file, 'w') as f:
        json.dump(output, f, indent=2)
    print(f"Saved group data to {output_file}")

def main():
    parser = argparse.ArgumentParser(description="Find spatial groups in shape data.")
    parser.add_argument('--input', default='output_data.json', help="Input JSON (instance registry)")
    parser.add_argument('--output', default='detected_groups.json', help="Output JSON (groups)")
    
    args = parser.parse_args()
    
    data = load_data(args.input)
    types, instances = find_spatial_groups(data)
    export_groups(types, instances, args.output)

if __name__ == "__main__":
    main()
